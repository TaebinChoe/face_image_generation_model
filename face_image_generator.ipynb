{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCH = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터 준비\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64), #얼굴이므로 가운데가 좋을 것\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root = './data', transform = transform)\n",
    "dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator(모조 화가) 클래스\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            #역합성곱 연산을 하여 입력의 크기를 늘려준다. 최종목표는 3*64*64이다.\n",
    "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),  #100*1*1 -> 512*4*4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False), #512*4*4 -> 256*8*8\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False), #256*8*8 -> 128*16*16\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "           \n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False), #128*16*16 -> 64*32*32\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False), #64*32*32 -> 3*64*64 \n",
    "            nn.Tanh()     \n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator(감별사) 클래스\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            #합성곱 연산을 하여 크기를 줄여준다 최종목표는 1*1*1이다.\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False), #3*64*64 -> 64*32*32\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False), #64*32*32 -> 128*16*16\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False), #128*16*16 -> 256*8*8\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False), #256*8*8 -> 512*4*4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False), #512*4*4 -> 1*1*1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#가중치 초기화 함수\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 출력 함수\n",
    "def show_generated_images(images, num_images=64):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Generated Images\")\n",
    "    images = vutils.make_grid(images[:num_images], padding=2, normalize=True)\n",
    "    images = np.transpose(images.cpu(), (1, 2, 0))\n",
    "    plt.imshow(images)\n",
    "    plt.show()\n",
    "\n",
    "#이미지 저장 함수\n",
    "def save_generated_images(images, num_images, epoch, idx):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Generated Images\")\n",
    "    images = vutils.make_grid(images[:num_images], padding=2, normalize=True)\n",
    "    images = np.transpose(images.cpu(), (1, 2, 0))\n",
    "    # plt.imshow(images)\n",
    "    fname = './output/image_'+str(epoch)+'_'+str(idx)+'.jpg'\n",
    "    plt.imsave(fname, images.numpy())\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 생성\n",
    "netG = Generator() \n",
    "netD = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#가중치 초기화\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG.to(device)\n",
    "netD.to(device)\n",
    "\n",
    "criterion = nn.BCELoss() #Binary Cross Entropy\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "fixed_noise = torch.randn(64, 100, 1, 1, device = device) #이미지 생성 중간 점검에 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10][0/1583] Loss_D: 0.8821 Loss_G: 6.3869\n",
      "[0/10][50/1583] Loss_D: 0.2535 Loss_G: 27.6500\n",
      "[0/10][100/1583] Loss_D: 0.4633 Loss_G: 9.5946\n",
      "[0/10][150/1583] Loss_D: 0.5024 Loss_G: 4.5657\n",
      "[0/10][200/1583] Loss_D: 0.3604 Loss_G: 3.9084\n",
      "[0/10][250/1583] Loss_D: 0.3524 Loss_G: 5.8282\n",
      "[0/10][300/1583] Loss_D: 0.6376 Loss_G: 5.0437\n",
      "[0/10][350/1583] Loss_D: 0.5566 Loss_G: 2.7458\n",
      "[0/10][400/1583] Loss_D: 0.3889 Loss_G: 4.5326\n",
      "[0/10][450/1583] Loss_D: 1.5843 Loss_G: 2.4811\n",
      "[0/10][500/1583] Loss_D: 0.5588 Loss_G: 3.7698\n",
      "[0/10][550/1583] Loss_D: 0.4487 Loss_G: 5.1489\n",
      "[0/10][600/1583] Loss_D: 0.9414 Loss_G: 5.8112\n",
      "[0/10][650/1583] Loss_D: 0.4494 Loss_G: 4.5196\n",
      "[0/10][700/1583] Loss_D: 1.1208 Loss_G: 7.9532\n",
      "[0/10][750/1583] Loss_D: 0.5686 Loss_G: 2.8373\n",
      "[0/10][800/1583] Loss_D: 0.2343 Loss_G: 4.9792\n",
      "[0/10][850/1583] Loss_D: 0.5722 Loss_G: 3.3445\n",
      "[0/10][900/1583] Loss_D: 0.4373 Loss_G: 4.3632\n",
      "[0/10][950/1583] Loss_D: 0.7310 Loss_G: 6.2940\n",
      "[0/10][1000/1583] Loss_D: 1.3751 Loss_G: 4.1279\n",
      "[0/10][1050/1583] Loss_D: 0.4190 Loss_G: 6.1136\n",
      "[0/10][1100/1583] Loss_D: 0.4493 Loss_G: 4.1879\n",
      "[0/10][1150/1583] Loss_D: 1.7388 Loss_G: 1.9813\n",
      "[0/10][1200/1583] Loss_D: 0.6420 Loss_G: 6.2129\n",
      "[0/10][1250/1583] Loss_D: 0.3400 Loss_G: 4.3911\n",
      "[0/10][1300/1583] Loss_D: 0.4384 Loss_G: 4.4827\n",
      "[0/10][1350/1583] Loss_D: 0.7177 Loss_G: 6.0079\n",
      "[0/10][1400/1583] Loss_D: 0.5350 Loss_G: 4.0109\n",
      "[0/10][1450/1583] Loss_D: 0.3150 Loss_G: 3.9256\n",
      "[0/10][1500/1583] Loss_D: 0.4163 Loss_G: 6.5128\n",
      "[0/10][1550/1583] Loss_D: 0.3615 Loss_G: 5.6500\n",
      "[1/10][0/1583] Loss_D: 0.3962 Loss_G: 3.8454\n",
      "[1/10][50/1583] Loss_D: 0.8546 Loss_G: 1.4314\n",
      "[1/10][100/1583] Loss_D: 0.6858 Loss_G: 6.4550\n",
      "[1/10][150/1583] Loss_D: 2.5657 Loss_G: 1.2846\n",
      "[1/10][200/1583] Loss_D: 0.3704 Loss_G: 5.9142\n",
      "[1/10][250/1583] Loss_D: 0.6076 Loss_G: 3.7764\n",
      "[1/10][300/1583] Loss_D: 0.3068 Loss_G: 4.3045\n",
      "[1/10][350/1583] Loss_D: 1.4518 Loss_G: 1.3821\n",
      "[1/10][400/1583] Loss_D: 0.9702 Loss_G: 7.2364\n",
      "[1/10][450/1583] Loss_D: 0.3186 Loss_G: 4.2580\n",
      "[1/10][500/1583] Loss_D: 0.3902 Loss_G: 3.4051\n",
      "[1/10][550/1583] Loss_D: 0.5709 Loss_G: 2.2436\n",
      "[1/10][600/1583] Loss_D: 0.7736 Loss_G: 2.6696\n",
      "[1/10][650/1583] Loss_D: 0.5670 Loss_G: 2.2326\n",
      "[1/10][700/1583] Loss_D: 0.5445 Loss_G: 2.2820\n",
      "[1/10][750/1583] Loss_D: 0.3263 Loss_G: 3.3599\n",
      "[1/10][800/1583] Loss_D: 2.9989 Loss_G: 6.7267\n",
      "[1/10][850/1583] Loss_D: 0.3550 Loss_G: 4.0860\n",
      "[1/10][900/1583] Loss_D: 0.4226 Loss_G: 2.6672\n",
      "[1/10][950/1583] Loss_D: 0.5231 Loss_G: 4.3865\n",
      "[1/10][1000/1583] Loss_D: 0.3802 Loss_G: 3.1365\n",
      "[1/10][1050/1583] Loss_D: 0.5642 Loss_G: 3.4682\n",
      "[1/10][1100/1583] Loss_D: 0.3991 Loss_G: 4.1583\n",
      "[1/10][1150/1583] Loss_D: 1.2626 Loss_G: 6.8238\n",
      "[1/10][1200/1583] Loss_D: 1.2321 Loss_G: 6.3072\n",
      "[1/10][1250/1583] Loss_D: 0.4986 Loss_G: 2.3002\n",
      "[1/10][1300/1583] Loss_D: 0.7842 Loss_G: 3.0577\n",
      "[1/10][1350/1583] Loss_D: 0.5522 Loss_G: 2.6975\n",
      "[1/10][1400/1583] Loss_D: 0.7419 Loss_G: 4.6018\n",
      "[1/10][1450/1583] Loss_D: 1.8940 Loss_G: 7.8211\n",
      "[1/10][1500/1583] Loss_D: 0.5246 Loss_G: 2.3550\n",
      "[1/10][1550/1583] Loss_D: 1.8109 Loss_G: 5.9695\n",
      "[2/10][0/1583] Loss_D: 0.4158 Loss_G: 2.8227\n",
      "[2/10][50/1583] Loss_D: 0.5359 Loss_G: 3.8538\n",
      "[2/10][100/1583] Loss_D: 0.4733 Loss_G: 3.3299\n",
      "[2/10][150/1583] Loss_D: 0.4865 Loss_G: 2.9615\n",
      "[2/10][200/1583] Loss_D: 0.6419 Loss_G: 1.7144\n",
      "[2/10][250/1583] Loss_D: 1.3586 Loss_G: 4.9174\n",
      "[2/10][300/1583] Loss_D: 0.6708 Loss_G: 3.6896\n",
      "[2/10][350/1583] Loss_D: 0.3993 Loss_G: 2.7225\n",
      "[2/10][400/1583] Loss_D: 0.4793 Loss_G: 2.1813\n",
      "[2/10][450/1583] Loss_D: 0.8405 Loss_G: 1.2946\n",
      "[2/10][500/1583] Loss_D: 0.7849 Loss_G: 1.6260\n",
      "[2/10][550/1583] Loss_D: 0.5803 Loss_G: 3.5051\n",
      "[2/10][600/1583] Loss_D: 0.8474 Loss_G: 2.9741\n",
      "[2/10][650/1583] Loss_D: 0.4538 Loss_G: 2.7512\n",
      "[2/10][700/1583] Loss_D: 0.7400 Loss_G: 3.3239\n",
      "[2/10][750/1583] Loss_D: 0.4173 Loss_G: 2.6151\n",
      "[2/10][800/1583] Loss_D: 0.8645 Loss_G: 1.9879\n",
      "[2/10][850/1583] Loss_D: 0.6085 Loss_G: 2.6279\n",
      "[2/10][900/1583] Loss_D: 0.4981 Loss_G: 1.8817\n",
      "[2/10][950/1583] Loss_D: 0.5811 Loss_G: 2.7219\n",
      "[2/10][1000/1583] Loss_D: 1.0721 Loss_G: 3.6507\n",
      "[2/10][1050/1583] Loss_D: 1.0543 Loss_G: 4.8657\n",
      "[2/10][1100/1583] Loss_D: 1.0492 Loss_G: 3.6326\n",
      "[2/10][1150/1583] Loss_D: 0.6220 Loss_G: 3.6847\n",
      "[2/10][1200/1583] Loss_D: 0.6658 Loss_G: 1.6592\n",
      "[2/10][1250/1583] Loss_D: 0.6588 Loss_G: 1.6566\n",
      "[2/10][1300/1583] Loss_D: 1.5546 Loss_G: 5.6957\n",
      "[2/10][1350/1583] Loss_D: 0.9846 Loss_G: 5.1075\n",
      "[2/10][1400/1583] Loss_D: 0.4887 Loss_G: 2.1971\n",
      "[2/10][1450/1583] Loss_D: 0.5625 Loss_G: 2.6492\n",
      "[2/10][1500/1583] Loss_D: 0.4570 Loss_G: 2.7192\n",
      "[2/10][1550/1583] Loss_D: 0.5588 Loss_G: 2.4264\n",
      "[3/10][0/1583] Loss_D: 1.4865 Loss_G: 0.8117\n",
      "[3/10][50/1583] Loss_D: 0.5622 Loss_G: 2.1126\n",
      "[3/10][100/1583] Loss_D: 0.5525 Loss_G: 2.0303\n",
      "[3/10][150/1583] Loss_D: 0.4514 Loss_G: 2.4317\n",
      "[3/10][200/1583] Loss_D: 0.6264 Loss_G: 3.0753\n",
      "[3/10][250/1583] Loss_D: 0.5296 Loss_G: 2.4020\n",
      "[3/10][300/1583] Loss_D: 1.3435 Loss_G: 4.9531\n",
      "[3/10][350/1583] Loss_D: 0.6003 Loss_G: 2.4330\n",
      "[3/10][400/1583] Loss_D: 0.8092 Loss_G: 1.4500\n",
      "[3/10][450/1583] Loss_D: 1.5682 Loss_G: 5.1820\n",
      "[3/10][500/1583] Loss_D: 0.9789 Loss_G: 3.8918\n",
      "[3/10][550/1583] Loss_D: 0.6139 Loss_G: 3.0688\n",
      "[3/10][600/1583] Loss_D: 1.1844 Loss_G: 3.8879\n",
      "[3/10][650/1583] Loss_D: 0.8909 Loss_G: 0.9765\n",
      "[3/10][700/1583] Loss_D: 1.1458 Loss_G: 1.8053\n",
      "[3/10][750/1583] Loss_D: 0.6483 Loss_G: 1.6189\n",
      "[3/10][800/1583] Loss_D: 0.7297 Loss_G: 3.3249\n",
      "[3/10][850/1583] Loss_D: 0.9011 Loss_G: 1.0291\n",
      "[3/10][900/1583] Loss_D: 0.6312 Loss_G: 2.7180\n",
      "[3/10][950/1583] Loss_D: 0.6094 Loss_G: 3.0679\n",
      "[3/10][1000/1583] Loss_D: 0.5938 Loss_G: 2.3873\n",
      "[3/10][1050/1583] Loss_D: 1.0742 Loss_G: 4.1588\n",
      "[3/10][1100/1583] Loss_D: 0.4874 Loss_G: 2.2688\n",
      "[3/10][1150/1583] Loss_D: 0.4873 Loss_G: 2.6479\n",
      "[3/10][1200/1583] Loss_D: 0.8749 Loss_G: 3.4123\n",
      "[3/10][1250/1583] Loss_D: 0.6013 Loss_G: 1.8198\n",
      "[3/10][1300/1583] Loss_D: 2.4847 Loss_G: 6.8211\n",
      "[3/10][1350/1583] Loss_D: 0.4108 Loss_G: 2.9041\n",
      "[3/10][1400/1583] Loss_D: 0.5315 Loss_G: 1.9796\n",
      "[3/10][1450/1583] Loss_D: 0.4492 Loss_G: 2.9085\n",
      "[3/10][1500/1583] Loss_D: 0.6111 Loss_G: 2.9146\n",
      "[3/10][1550/1583] Loss_D: 0.6608 Loss_G: 2.4814\n",
      "[4/10][0/1583] Loss_D: 0.7098 Loss_G: 3.6381\n",
      "[4/10][50/1583] Loss_D: 0.9037 Loss_G: 4.9095\n",
      "[4/10][100/1583] Loss_D: 0.5677 Loss_G: 1.8676\n",
      "[4/10][150/1583] Loss_D: 0.5586 Loss_G: 2.2503\n",
      "[4/10][200/1583] Loss_D: 0.9431 Loss_G: 3.9780\n",
      "[4/10][250/1583] Loss_D: 0.4647 Loss_G: 2.7655\n",
      "[4/10][300/1583] Loss_D: 0.7220 Loss_G: 3.3366\n",
      "[4/10][350/1583] Loss_D: 0.6379 Loss_G: 1.5474\n",
      "[4/10][400/1583] Loss_D: 0.6744 Loss_G: 1.4969\n",
      "[4/10][450/1583] Loss_D: 0.5647 Loss_G: 1.8056\n",
      "[4/10][500/1583] Loss_D: 0.4388 Loss_G: 3.0467\n",
      "[4/10][550/1583] Loss_D: 0.6844 Loss_G: 3.5380\n",
      "[4/10][600/1583] Loss_D: 0.7271 Loss_G: 1.8125\n",
      "[4/10][650/1583] Loss_D: 0.5686 Loss_G: 1.7273\n",
      "[4/10][700/1583] Loss_D: 0.5724 Loss_G: 2.4718\n",
      "[4/10][750/1583] Loss_D: 0.5771 Loss_G: 2.8235\n",
      "[4/10][800/1583] Loss_D: 0.5470 Loss_G: 2.8244\n",
      "[4/10][850/1583] Loss_D: 0.6653 Loss_G: 1.8496\n",
      "[4/10][900/1583] Loss_D: 0.6603 Loss_G: 3.3199\n",
      "[4/10][950/1583] Loss_D: 0.4826 Loss_G: 3.2389\n",
      "[4/10][1000/1583] Loss_D: 0.7529 Loss_G: 4.3733\n",
      "[4/10][1050/1583] Loss_D: 0.4212 Loss_G: 2.4431\n",
      "[4/10][1100/1583] Loss_D: 0.6411 Loss_G: 3.9689\n",
      "[4/10][1150/1583] Loss_D: 0.9072 Loss_G: 1.4923\n",
      "[4/10][1200/1583] Loss_D: 0.6017 Loss_G: 3.1413\n",
      "[4/10][1250/1583] Loss_D: 0.5183 Loss_G: 1.9664\n",
      "[4/10][1300/1583] Loss_D: 0.7550 Loss_G: 3.7061\n",
      "[4/10][1350/1583] Loss_D: 0.4669 Loss_G: 3.6140\n",
      "[4/10][1400/1583] Loss_D: 0.4904 Loss_G: 2.0233\n",
      "[4/10][1450/1583] Loss_D: 0.7376 Loss_G: 0.9013\n",
      "[4/10][1500/1583] Loss_D: 0.8727 Loss_G: 1.1925\n",
      "[4/10][1550/1583] Loss_D: 0.5918 Loss_G: 2.5713\n",
      "[5/10][0/1583] Loss_D: 0.7018 Loss_G: 1.5472\n",
      "[5/10][50/1583] Loss_D: 0.8290 Loss_G: 1.5911\n",
      "[5/10][100/1583] Loss_D: 1.2198 Loss_G: 4.9401\n",
      "[5/10][150/1583] Loss_D: 0.6523 Loss_G: 1.9127\n",
      "[5/10][200/1583] Loss_D: 0.4560 Loss_G: 2.7641\n",
      "[5/10][250/1583] Loss_D: 0.6527 Loss_G: 1.6300\n",
      "[5/10][300/1583] Loss_D: 0.5921 Loss_G: 3.3982\n",
      "[5/10][350/1583] Loss_D: 0.6826 Loss_G: 3.6399\n",
      "[5/10][400/1583] Loss_D: 0.4852 Loss_G: 2.3391\n",
      "[5/10][450/1583] Loss_D: 0.4606 Loss_G: 2.4878\n",
      "[5/10][500/1583] Loss_D: 1.0390 Loss_G: 1.3365\n",
      "[5/10][550/1583] Loss_D: 0.6115 Loss_G: 2.9141\n",
      "[5/10][600/1583] Loss_D: 1.0493 Loss_G: 0.7827\n",
      "[5/10][650/1583] Loss_D: 0.8042 Loss_G: 4.0522\n",
      "[5/10][700/1583] Loss_D: 0.9433 Loss_G: 4.1552\n",
      "[5/10][750/1583] Loss_D: 0.4736 Loss_G: 1.9615\n",
      "[5/10][800/1583] Loss_D: 0.4174 Loss_G: 2.6197\n",
      "[5/10][850/1583] Loss_D: 1.2575 Loss_G: 4.5131\n",
      "[5/10][900/1583] Loss_D: 0.6296 Loss_G: 1.6141\n",
      "[5/10][950/1583] Loss_D: 1.1446 Loss_G: 3.4784\n",
      "[5/10][1000/1583] Loss_D: 0.5935 Loss_G: 2.1368\n",
      "[5/10][1050/1583] Loss_D: 0.5158 Loss_G: 2.6718\n",
      "[5/10][1100/1583] Loss_D: 0.5269 Loss_G: 1.6823\n",
      "[5/10][1150/1583] Loss_D: 0.4324 Loss_G: 2.9411\n",
      "[5/10][1200/1583] Loss_D: 0.5642 Loss_G: 3.3320\n",
      "[5/10][1250/1583] Loss_D: 1.8081 Loss_G: 6.1389\n",
      "[5/10][1300/1583] Loss_D: 0.5312 Loss_G: 1.8215\n",
      "[5/10][1350/1583] Loss_D: 0.7074 Loss_G: 1.4988\n",
      "[5/10][1400/1583] Loss_D: 1.1446 Loss_G: 0.4388\n",
      "[5/10][1450/1583] Loss_D: 0.7350 Loss_G: 1.8245\n",
      "[5/10][1500/1583] Loss_D: 0.4524 Loss_G: 2.1623\n",
      "[5/10][1550/1583] Loss_D: 0.5852 Loss_G: 1.6322\n",
      "[6/10][0/1583] Loss_D: 0.4746 Loss_G: 1.9517\n",
      "[6/10][50/1583] Loss_D: 0.8954 Loss_G: 0.7523\n",
      "[6/10][100/1583] Loss_D: 0.9341 Loss_G: 1.2833\n",
      "[6/10][150/1583] Loss_D: 0.5913 Loss_G: 1.4213\n",
      "[6/10][200/1583] Loss_D: 3.0783 Loss_G: 0.5562\n",
      "[6/10][250/1583] Loss_D: 0.3825 Loss_G: 2.9598\n",
      "[6/10][300/1583] Loss_D: 0.3617 Loss_G: 3.3850\n",
      "[6/10][350/1583] Loss_D: 0.6497 Loss_G: 1.8131\n",
      "[6/10][400/1583] Loss_D: 0.6232 Loss_G: 2.2924\n",
      "[6/10][450/1583] Loss_D: 0.4470 Loss_G: 2.4627\n",
      "[6/10][500/1583] Loss_D: 0.4863 Loss_G: 2.9619\n",
      "[6/10][550/1583] Loss_D: 0.3949 Loss_G: 2.8431\n",
      "[6/10][600/1583] Loss_D: 0.7494 Loss_G: 1.2732\n",
      "[6/10][650/1583] Loss_D: 0.6298 Loss_G: 2.4956\n",
      "[6/10][700/1583] Loss_D: 1.2845 Loss_G: 1.0765\n",
      "[6/10][750/1583] Loss_D: 0.6126 Loss_G: 1.4167\n",
      "[6/10][800/1583] Loss_D: 0.2637 Loss_G: 3.3441\n",
      "[6/10][850/1583] Loss_D: 0.4982 Loss_G: 2.6001\n",
      "[6/10][900/1583] Loss_D: 0.7121 Loss_G: 3.1464\n",
      "[6/10][950/1583] Loss_D: 0.6201 Loss_G: 1.4667\n",
      "[6/10][1000/1583] Loss_D: 0.9054 Loss_G: 3.9601\n",
      "[6/10][1050/1583] Loss_D: 0.7420 Loss_G: 5.2647\n",
      "[6/10][1100/1583] Loss_D: 0.5904 Loss_G: 1.6791\n",
      "[6/10][1150/1583] Loss_D: 0.5697 Loss_G: 2.5748\n",
      "[6/10][1200/1583] Loss_D: 0.3984 Loss_G: 3.1095\n",
      "[6/10][1250/1583] Loss_D: 0.4493 Loss_G: 3.3296\n",
      "[6/10][1300/1583] Loss_D: 0.4152 Loss_G: 2.5711\n",
      "[6/10][1350/1583] Loss_D: 0.3697 Loss_G: 2.9355\n",
      "[6/10][1400/1583] Loss_D: 0.8969 Loss_G: 4.8213\n",
      "[6/10][1450/1583] Loss_D: 0.4708 Loss_G: 3.5265\n",
      "[6/10][1500/1583] Loss_D: 0.9421 Loss_G: 1.5473\n",
      "[6/10][1550/1583] Loss_D: 0.4841 Loss_G: 3.1132\n",
      "[7/10][0/1583] Loss_D: 1.5701 Loss_G: 4.4542\n",
      "[7/10][50/1583] Loss_D: 0.3624 Loss_G: 3.0613\n",
      "[7/10][100/1583] Loss_D: 0.5973 Loss_G: 2.2899\n",
      "[7/10][150/1583] Loss_D: 0.4968 Loss_G: 1.8912\n",
      "[7/10][200/1583] Loss_D: 0.5091 Loss_G: 2.7814\n",
      "[7/10][250/1583] Loss_D: 1.2341 Loss_G: 4.6219\n",
      "[7/10][300/1583] Loss_D: 0.3569 Loss_G: 3.7708\n",
      "[7/10][350/1583] Loss_D: 0.3188 Loss_G: 3.0511\n",
      "[7/10][400/1583] Loss_D: 0.7281 Loss_G: 1.0779\n",
      "[7/10][450/1583] Loss_D: 0.4076 Loss_G: 2.7391\n",
      "[7/10][500/1583] Loss_D: 0.4470 Loss_G: 2.1622\n",
      "[7/10][550/1583] Loss_D: 1.0075 Loss_G: 0.8514\n",
      "[7/10][600/1583] Loss_D: 0.8135 Loss_G: 1.8821\n",
      "[7/10][650/1583] Loss_D: 0.4211 Loss_G: 3.4506\n",
      "[7/10][700/1583] Loss_D: 3.4900 Loss_G: 0.2927\n",
      "[7/10][750/1583] Loss_D: 0.8145 Loss_G: 0.9986\n",
      "[7/10][800/1583] Loss_D: 0.7295 Loss_G: 1.5685\n",
      "[7/10][850/1583] Loss_D: 0.3524 Loss_G: 3.5836\n",
      "[7/10][900/1583] Loss_D: 0.6051 Loss_G: 1.6368\n",
      "[7/10][950/1583] Loss_D: 0.8132 Loss_G: 4.4158\n",
      "[7/10][1000/1583] Loss_D: 0.5086 Loss_G: 2.8811\n",
      "[7/10][1050/1583] Loss_D: 0.9694 Loss_G: 1.0483\n",
      "[7/10][1100/1583] Loss_D: 0.5030 Loss_G: 4.0808\n",
      "[7/10][1150/1583] Loss_D: 0.4437 Loss_G: 2.9586\n",
      "[7/10][1200/1583] Loss_D: 0.5750 Loss_G: 1.9487\n",
      "[7/10][1250/1583] Loss_D: 0.3501 Loss_G: 3.1087\n",
      "[7/10][1300/1583] Loss_D: 0.4647 Loss_G: 3.5631\n",
      "[7/10][1350/1583] Loss_D: 0.5756 Loss_G: 2.0709\n",
      "[7/10][1400/1583] Loss_D: 0.5185 Loss_G: 4.1131\n",
      "[7/10][1450/1583] Loss_D: 0.8267 Loss_G: 5.2571\n",
      "[7/10][1500/1583] Loss_D: 0.8237 Loss_G: 4.0135\n",
      "[7/10][1550/1583] Loss_D: 0.6734 Loss_G: 3.8883\n",
      "[8/10][0/1583] Loss_D: 0.4583 Loss_G: 3.7026\n",
      "[8/10][50/1583] Loss_D: 0.6338 Loss_G: 1.3945\n",
      "[8/10][100/1583] Loss_D: 1.0193 Loss_G: 5.0629\n",
      "[8/10][150/1583] Loss_D: 0.4846 Loss_G: 3.1546\n",
      "[8/10][200/1583] Loss_D: 1.0783 Loss_G: 0.7058\n",
      "[8/10][250/1583] Loss_D: 0.5486 Loss_G: 1.7738\n",
      "[8/10][300/1583] Loss_D: 0.3080 Loss_G: 2.9573\n",
      "[8/10][350/1583] Loss_D: 0.5149 Loss_G: 4.6598\n",
      "[8/10][400/1583] Loss_D: 0.6223 Loss_G: 0.5115\n",
      "[8/10][450/1583] Loss_D: 0.5626 Loss_G: 3.1315\n",
      "[8/10][500/1583] Loss_D: 0.3993 Loss_G: 3.1516\n",
      "[8/10][550/1583] Loss_D: 0.3528 Loss_G: 3.2974\n",
      "[8/10][600/1583] Loss_D: 0.3730 Loss_G: 3.8431\n",
      "[8/10][650/1583] Loss_D: 0.3997 Loss_G: 3.3561\n",
      "[8/10][700/1583] Loss_D: 0.5920 Loss_G: 1.9766\n",
      "[8/10][750/1583] Loss_D: 1.8716 Loss_G: 0.2943\n",
      "[8/10][800/1583] Loss_D: 0.4690 Loss_G: 3.2576\n",
      "[8/10][850/1583] Loss_D: 0.3347 Loss_G: 2.7616\n",
      "[8/10][900/1583] Loss_D: 0.4876 Loss_G: 2.0952\n",
      "[8/10][950/1583] Loss_D: 0.7924 Loss_G: 1.3314\n",
      "[8/10][1000/1583] Loss_D: 0.4997 Loss_G: 1.7680\n",
      "[8/10][1050/1583] Loss_D: 0.4118 Loss_G: 3.4015\n",
      "[8/10][1100/1583] Loss_D: 0.2531 Loss_G: 3.0843\n",
      "[8/10][1150/1583] Loss_D: 0.7259 Loss_G: 2.8924\n",
      "[8/10][1200/1583] Loss_D: 0.9112 Loss_G: 5.5771\n",
      "[8/10][1250/1583] Loss_D: 0.3330 Loss_G: 2.3563\n",
      "[8/10][1300/1583] Loss_D: 0.3031 Loss_G: 2.6361\n",
      "[8/10][1350/1583] Loss_D: 1.2437 Loss_G: 0.9850\n",
      "[8/10][1400/1583] Loss_D: 0.5262 Loss_G: 2.4788\n",
      "[8/10][1450/1583] Loss_D: 0.4164 Loss_G: 2.7675\n",
      "[8/10][1500/1583] Loss_D: 0.2076 Loss_G: 3.6539\n",
      "[8/10][1550/1583] Loss_D: 0.3217 Loss_G: 4.3569\n",
      "[9/10][0/1583] Loss_D: 0.7182 Loss_G: 3.8235\n",
      "[9/10][50/1583] Loss_D: 1.0785 Loss_G: 1.3611\n",
      "[9/10][100/1583] Loss_D: 0.4021 Loss_G: 2.1578\n",
      "[9/10][150/1583] Loss_D: 0.5044 Loss_G: 1.8968\n",
      "[9/10][200/1583] Loss_D: 0.8401 Loss_G: 1.9376\n",
      "[9/10][250/1583] Loss_D: 0.3790 Loss_G: 2.6012\n",
      "[9/10][300/1583] Loss_D: 0.3551 Loss_G: 3.4506\n",
      "[9/10][350/1583] Loss_D: 1.5408 Loss_G: 1.0882\n",
      "[9/10][400/1583] Loss_D: 0.5989 Loss_G: 3.9635\n",
      "[9/10][450/1583] Loss_D: 0.3206 Loss_G: 2.4877\n",
      "[9/10][500/1583] Loss_D: 0.6953 Loss_G: 1.4595\n",
      "[9/10][550/1583] Loss_D: 0.4579 Loss_G: 3.3200\n",
      "[9/10][600/1583] Loss_D: 0.4664 Loss_G: 1.7302\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        #Discriminator 먼저\n",
    "        netD.zero_grad()\n",
    "        real_data = data[0].to(device) #실제 사진\n",
    "        batch_size = real_data.size(0) \n",
    "        real_label = torch.full((batch_size,), 1, dtype=torch.float, device = device) #정답은 1\n",
    "        fake_label = torch.full((batch_size,), 0, dtype=torch.float, device = device) #정답은 0\n",
    "\n",
    "        output = netD(real_data).view(-1) #순전파로 진짜일 확률 계산\n",
    "        errD_real = criterion(output, real_label)\n",
    "        errD_real.backward() #역전파로 그라디언트 계산\n",
    "\n",
    "        rand_input = torch.randn(batch_size, 100, 1, 1, device=device) #100*1 크기의 랜덤 tensor\n",
    "        fake_data = netG(rand_input)\n",
    "        output = netD(fake_data.detach()).view(-1) #가짜사진이 진짜라고 생각하는 확률\n",
    "\n",
    "        errD_fake = criterion(output, fake_label)\n",
    "        errD_fake.backward() #역전파로 그라디언트 계산\n",
    "\n",
    "        errD = errD_real + errD_fake #이 둘을 합친것이 Discriminator의 error\n",
    "        optimizerD.step() #갱신\n",
    "\n",
    "        #Generator도 학습\n",
    "        netG.zero_grad()\n",
    "        output = netD(fake_data).view(-1) #가짜사진이 진짜라고 생각하는 확률\n",
    "        errG = criterion(output, real_label) #ouput이 1이 높을 수록 그럴듯하게 잘 만든것 -> 손실이 작음\n",
    "        errG.backward()\n",
    "        optimizerG.step() #갱신\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f'\n",
    "                  % (epoch, EPOCH, i, len(dataloader), errD.item(), errG.item()))\n",
    "            fake_images = netG(fixed_noise)\n",
    "            save_generated_images(fake_images, 64, epoch=epoch, idx=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시각화\n",
    "fake_images = netG(fixed_noise)\n",
    "show_generated_images(fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1+cu118'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.15.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\choe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
